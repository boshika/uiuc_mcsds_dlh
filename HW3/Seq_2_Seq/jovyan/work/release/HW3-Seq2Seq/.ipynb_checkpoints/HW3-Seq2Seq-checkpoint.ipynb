{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "15f5c6b26d4c149c0484e4b20e803cce",
     "grade": false,
     "grade_id": "cell-079a6526398a85d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# HW3 Seq2Seq\n",
    "\n",
    "In this question, you will use Seq2seq autoencoder model to generate patient EHR embedding and use these embeddigns to conduct unsupervised patient clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ba17b08f650c9433337e15531a0ee014",
     "grade": false,
     "grade_id": "cell-e559bcf016c4584e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T17:42:34.574573Z",
     "start_time": "2020-12-22T17:42:34.156244Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "57610de3a957fd0e56596e628377bd78",
     "grade": false,
     "grade_id": "cell-662d67c8f89d61b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T17:42:34.580083Z",
     "start_time": "2020-12-22T17:42:34.576200Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4774fd0b820a8f5b922d1965c3a1eab3",
     "grade": false,
     "grade_id": "cell-9762a8c40656dc06",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# set seed\n",
    "seed = 24\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9916035c8d6409007a26f503ae4b6b0a",
     "grade": false,
     "grade_id": "cell-f8fd0a0bdbdbd54e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"../HW3-Seq2Seq-lib/data/\"\n",
    "\n",
    "assert os.path.isdir(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e3c6c5e5e3e2f994e259a64f245cb35c",
     "grade": false,
     "grade_id": "cell-21b2fb2dbf1ff2e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3ce41d541f7fdfcb14ce45578fad5288",
     "grade": false,
     "grade_id": "cell-20d1c2d6fd977a22",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1 Load MIMIC-III data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "730cf19ae92f23835aa0402ad030661c",
     "grade": false,
     "grade_id": "cell-572524c6438cfdcc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We will be using the *ADMISSIONS*, *DIAGNOSES_ICD*, and *PATIENTS* tables from [MIMIC-III](https://mimic.physionet.org/gettingstarted/access/) dataset. Here is an overview of the three tables.\n",
    "\n",
    "-  *ADMISSIONS*: Define a patientâ€™s hospital admission, HADM_ID.\n",
    "- *DIAGNOSES_ICD*: Contains ICD diagnoses for patients, most notably ICD-9 diagnoses.\n",
    "- *PATIENTS*: Defines each SUBJECT_ID in the database, i.e. defines a single patient.\n",
    "\n",
    "The data has been preprocessed for you. Let us load them and take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T17:42:34.629045Z",
     "start_time": "2020-12-22T17:42:34.582014Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77b676f4e55c669249063cc67a279c56",
     "grade": false,
     "grade_id": "cell-dd5e81b9b8c115dd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "pids = pickle.load(open(f'{DATA_PATH}/mimic3.pids', 'rb'))\n",
    "dates = pickle.load(open(f'{DATA_PATH}/mimic3.dates', 'rb'))\n",
    "morts = pickle.load(open(f'{DATA_PATH}/mimic3.morts', 'rb'))\n",
    "seqs = pickle.load(open(f'{DATA_PATH}/mimic3.3digitICD9.seqs', 'rb'))\n",
    "types = pickle.load(open(f'{DATA_PATH}/mimic3.3digitICD9.types', 'rb'))\n",
    "rtypes = dict([(v,k) for k,v in types.items()])\n",
    "\n",
    "assert len(pids) == len(dates) == len(morts) == len(seqs) == 7537\n",
    "assert len(types) == 942"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f05022ff8b008c8653a12accf5e971f",
     "grade": false,
     "grade_id": "cell-8ea7106e7baf916e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "where\n",
    "\n",
    "- `pids`: contains the patient ids\n",
    "- `dates`: contains a list of admission dates for each patient\n",
    "- `morts`: contains the mortality information (0: alive, 1: dead)\n",
    "- `seqs`: contains a list of ICD-9 labels for admission of each patient\n",
    "- `types`: contains the map from 3-digit ICD-9 codes to ICD-9 labels\n",
    "- `rtypes`: contains the map from ICD-9 labels to 3-digit ICD-9 codes\n",
    "\n",
    "Let us take a patient as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T17:42:54.943384Z",
     "start_time": "2020-12-22T17:42:54.938299Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "667c595373e3e452bc6acc28388b27c2",
     "grade": false,
     "grade_id": "cell-c5e10739d77ed1fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: 362\n",
      "Mortality: 0\n",
      "# of admissions: 2\n",
      "\t0-th admission date: 2112-07-10 02:31:00\n",
      "\t0-th admission diagnosis labels: [77, 3, 78, 79, 45, 15, 80, 81]\n",
      "\t0-th admission diagnosis codes: ['D_E885', 'D_401', 'D_397', 'D_396', 'D_599', 'D_427', 'D_253', 'D_852']\n",
      "\t1-th admission date: 2112-07-28 17:08:00\n",
      "\t1-th admission diagnosis labels: [77, 3, 5, 15, 17, 81]\n",
      "\t1-th admission diagnosis codes: ['D_E885', 'D_401', 'D_424', 'D_427', 'D_428', 'D_852']\n"
     ]
    }
   ],
   "source": [
    "# take the 5-th patient as an example\n",
    "\n",
    "print(\"Patient ID:\", pids[5])\n",
    "print(\"Mortality:\", morts[5])\n",
    "print(\"# of admissions:\", len(dates[5]))\n",
    "for visit in range(len(dates[5])):\n",
    "    print(f\"\\t{visit}-th admission date:\", dates[5][visit])\n",
    "    print(f\"\\t{visit}-th admission diagnosis labels:\", seqs[5][visit])\n",
    "    print(f\"\\t{visit}-th admission diagnosis codes:\", [rtypes[label] for label in seqs[5][visit]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c34ca2ea657635028b72c66ba75fcd92",
     "grade": false,
     "grade_id": "cell-bca6680fe2226e07",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Note that `seqs` is a list of list of list. That is, `seqs[i][j][k]` gives you the k-th diagnosis codes for the j-th visit for the i-th patient.\n",
    "\n",
    "And you can look up the meaning of the ICD-9 code online. For example, `D_427` represetns *cardiac dysrhythmias*.\n",
    "\n",
    "Further, let see number of mortalities cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T17:42:55.278790Z",
     "start_time": "2020-12-22T17:42:55.275827Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "868a4ab63b90e66b64fad6a70c729678",
     "grade": false,
     "grade_id": "cell-73c9c7065254f3e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of mortalities: 2825\n",
      "ratio of mortalities: 0.37\n"
     ]
    }
   ],
   "source": [
    "print(\"number of mortalities:\", sum(morts))\n",
    "print(\"ratio of mortalities: %.2f\" % (sum(morts) / len(morts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ad811c829262a858b528170e34ce0b38",
     "grade": false,
     "grade_id": "cell-9797093f8f141582",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For the sake of computational efficiency, we will only use the diagnosis that appears more than or equal to 50 times in `seqs`. We need first store these frequent diagnosis labels into list `freq_codes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T17:42:55.659097Z",
     "start_time": "2020-12-22T17:42:55.600892Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "108b30e09886dac0d303ed04d85ea192",
     "grade": false,
     "grade_id": "cell-b18774a2ebec35dc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "freq_codes = []\n",
    "\n",
    "'''\n",
    "Append all codes that appears more than 50 times in freq_codes list.\n",
    "'''\n",
    "\n",
    "cnt_dict = {}\n",
    "for i in range(len(seqs)):\n",
    "    for j in range(len(seqs[i])):\n",
    "        for each_code in seqs[i][j]:\n",
    "            if each_code not in cnt_dict:\n",
    "                cnt_dict[each_code] = 1\n",
    "            else:\n",
    "                cnt_dict[each_code] += 1\n",
    "\n",
    "for each_code in cnt_dict:\n",
    "    if cnt_dict[each_code] >= 50:\n",
    "        freq_codes.append(each_code)\n",
    "        \n",
    "assert len(freq_codes) == 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "759dc445a5705fc80f7b08ca48768dcc",
     "grade": false,
     "grade_id": "cell-4045ed0f1f4b9687",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "code2idx = {code: idx for idx, code in enumerate(freq_codes)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "78dfb1743fe01ea6ff0744caf97e1c29",
     "grade": false,
     "grade_id": "cell-df8fb1015ec538bc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2 Build the dataset [20 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a4bc992b0507da972a64d864a09fd422",
     "grade": false,
     "grade_id": "cell-2a4a520635a7d2b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.1 Custom the dataset  [5 points]\n",
    "First, let us implement a custom dataset using PyTorch class `Dataset`, which will characterize the key features of the dataset we want to generate.\n",
    "\n",
    "We will use the sequences of diagnosis codes `seqs` as input and mortality `morts` as output.\n",
    "\n",
    "Note that we can still use `TorchText` as it provides a generic way to deal with sequential data. But we will implement the `Dataset` from scratch this time so that you can have more hands-on experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T17:42:56.225930Z",
     "start_time": "2020-12-22T17:42:56.221716Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, seqs, morts):\n",
    "        self.x = seqs\n",
    "        self.y = morts\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        TODO: Return the number of samples (i.e. patients).\n",
    "        \"\"\"\n",
    "        \n",
    "        # your code here\n",
    "        return len(self.x)\n",
    "#         raise NotImplementedError\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        \"\"\"\n",
    "        TODO: Generates one sample of data.\n",
    "        \n",
    "        Note that you DO NOT need to covert them to tensor as we will do this later.\n",
    "        \"\"\"\n",
    "        \n",
    "        # your code here\n",
    "        return self.x[index], self.y[index]\n",
    "        \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T17:42:56.420168Z",
     "start_time": "2020-12-22T17:42:56.378321Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb3504c5cb2fbfd40e07cc7525dec65d",
     "grade": true,
     "grade_id": "cell-2cdf5a1e3b59dd72",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "dataset = CustomDataset(seqs, morts)\n",
    "assert len(dataset) == 7537\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4a9b1220b1fd6f6972007807960d75b5",
     "grade": false,
     "grade_id": "cell-c9b3a70f18db1272",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.2 Collate Function [10 points]\n",
    "\n",
    "As you note that, we do not convert the data to tensor in the built `CustomDataset`. Instead, we will do this using a collate function `collate_fn()`. \n",
    "\n",
    "This collate function `collate_fn()` will be called by `DataLoader` after fetching a list of samples using the indices from `CustomDataset` to collate the list of samples into batches.\n",
    "\n",
    "For example, assume the `DataLoader` gets a list of two samples.\n",
    "\n",
    "```\n",
    "[ [ [0, 1, 2], [4, 0] ], \n",
    "  [ [2, 3], [1], [1, 4] ] ]\n",
    "```\n",
    "\n",
    "where the first sample has two visits `[0, 1, 2]` and `[4, 0]` and the second sample has three visits `[2, 3]`, `[1]`, and `[4, 1]`.\n",
    "\n",
    "The collate function `collate_fn()` is supposed to pad them into a multi-hot vector with shape (2, 3, 5), where 3 is the maximum number of visits, and 5 is the number of total diagnosis codes.\n",
    "\n",
    "``` \n",
    "[ [ [1, 1, 1, 0, 0], [0, 0, 0, 0, 1], [0, 0, 0, 0, 0] ],\n",
    "  [ [0, 0, 1, 1, 0], [0, 1, 0, 0, 0], [0, 1, 0, 0, 1] ] ]\n",
    "```\n",
    "\n",
    "Further, the padding information will be stored in a mask with the shape (2, 3), where 1 indicates that the visit at this position is from the original input, and 0 indicates that the visit at this position is the padded value.\n",
    "\n",
    "```\n",
    "[ [1, 1, 0], \n",
    "  [1, 1, 1] ]\n",
    "```\n",
    "\n",
    "We need to pad the sequences into the same length so that we can do batch training on GPU. And we also need this mask so that when training, we can ignored the padded value as they actually do not contain any information.\n",
    "\n",
    "We only keep the codes that in the `freq_codes` list and drop other codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 13, 14: 14, 15: 15, 16: 16, 17: 17, 18: 18, 19: 19, 20: 20, 21: 21, 22: 22, 23: 23, 24: 24, 25: 25, 26: 26, 27: 27, 28: 28, 29: 29, 30: 30, 31: 31, 32: 32, 33: 33, 34: 34, 35: 35, 36: 36, 37: 37, 38: 38, 39: 39, 40: 40, 41: 41, 42: 42, 43: 43, 44: 44, 45: 45, 46: 46, 47: 47, 48: 48, 49: 49, 50: 50, 51: 51, 52: 52, 53: 53, 54: 54, 55: 55, 56: 56, 57: 57, 58: 58, 59: 59, 60: 60, 61: 61, 62: 62, 63: 63, 64: 64, 65: 65, 66: 66, 67: 67, 68: 68, 69: 69, 70: 70, 71: 71, 72: 72, 73: 73, 74: 74, 75: 75, 76: 76, 77: 77, 78: 78, 79: 79, 80: 80, 81: 81, 82: 82, 83: 83, 84: 84, 85: 85, 86: 86, 87: 87, 88: 88, 89: 89, 90: 90, 91: 91, 92: 92, 93: 93, 96: 94, 97: 95, 98: 96, 99: 97, 100: 98, 102: 99, 103: 100, 104: 101, 105: 102, 106: 103, 107: 104, 108: 105, 109: 106, 110: 107, 111: 108, 113: 109, 114: 110, 115: 111, 116: 112, 117: 113, 118: 114, 119: 115, 120: 116, 121: 117, 122: 118, 123: 119, 124: 120, 125: 121, 126: 122, 127: 123, 128: 124, 129: 125, 130: 126, 131: 127, 133: 128, 134: 129, 139: 130, 140: 131, 141: 132, 142: 133, 143: 134, 145: 135, 146: 136, 148: 137, 149: 138, 150: 139, 151: 140, 152: 141, 154: 142, 155: 143, 156: 144, 157: 145, 158: 146, 159: 147, 161: 148, 162: 149, 163: 150, 164: 151, 165: 152, 166: 153, 168: 154, 170: 155, 171: 156, 172: 157, 173: 158, 174: 159, 175: 160, 176: 161, 177: 162, 178: 163, 179: 164, 181: 165, 182: 166, 183: 167, 184: 168, 185: 169, 186: 170, 187: 171, 189: 172, 190: 173, 191: 174, 192: 175, 193: 176, 194: 177, 195: 178, 196: 179, 197: 180, 198: 181, 199: 182, 200: 183, 201: 184, 202: 185, 204: 186, 206: 187, 207: 188, 208: 189, 210: 190, 211: 191, 212: 192, 213: 193, 214: 194, 215: 195, 217: 196, 218: 197, 219: 198, 220: 199, 221: 200, 222: 201, 223: 202, 224: 203, 225: 204, 226: 205, 227: 206, 228: 207, 230: 208, 231: 209, 232: 210, 233: 211, 234: 212, 235: 213, 236: 214, 237: 215, 238: 216, 239: 217, 240: 218, 245: 219, 246: 220, 247: 221, 248: 222, 249: 223, 250: 224, 251: 225, 255: 226, 256: 227, 260: 228, 261: 229, 262: 230, 264: 231, 266: 232, 267: 233, 268: 234, 269: 235, 271: 236, 272: 237, 273: 238, 275: 239, 276: 240, 278: 241, 281: 242, 282: 243, 285: 244, 286: 245, 287: 246, 288: 247, 289: 248, 290: 249, 292: 250, 293: 251, 294: 252, 295: 253, 296: 254, 297: 255, 299: 256, 300: 257, 301: 258, 302: 259, 304: 260, 305: 261, 306: 262, 307: 263, 308: 264, 309: 265, 310: 266, 311: 267, 312: 268, 313: 269, 316: 270, 317: 271, 318: 272, 319: 273, 320: 274, 321: 275, 323: 276, 327: 277, 329: 278, 330: 279, 331: 280, 334: 281, 337: 282, 344: 283, 345: 284, 348: 285, 352: 286, 353: 287, 355: 288, 357: 289, 359: 290, 360: 291, 361: 292, 363: 293, 364: 294, 365: 295, 366: 296, 367: 297, 369: 298, 371: 299, 372: 300, 373: 301, 374: 302, 375: 303, 380: 304, 381: 305, 382: 306, 384: 307, 385: 308, 386: 309, 389: 310, 391: 311, 392: 312, 394: 313, 398: 314, 401: 315, 402: 316, 403: 317, 405: 318, 406: 319, 410: 320, 413: 321, 414: 322, 420: 323, 425: 324, 427: 325, 429: 326, 430: 327, 433: 328, 436: 329, 437: 330, 438: 331, 440: 332, 441: 333, 444: 334, 452: 335, 454: 336, 455: 337, 458: 338, 460: 339, 462: 340, 471: 341, 472: 342, 474: 343, 478: 344, 479: 345, 493: 346, 496: 347, 503: 348, 506: 349, 511: 350, 521: 351, 539: 352, 540: 353, 545: 354, 556: 355, 557: 356, 564: 357, 579: 358, 745: 359}\n"
     ]
    }
   ],
   "source": [
    "print(code2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T17:42:56.758342Z",
     "start_time": "2020-12-22T17:42:56.752963Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    \"\"\"\n",
    "    Collate the the list of samples into batches. For each patient, you need to pad the diagnosis\n",
    "        sequences to the sample shape (max # visits, len(freq_codes)). The padding infomation\n",
    "        is stored in `mask`.\n",
    "    \n",
    "    Arguments:\n",
    "        data: a list of samples fetched from `CustomDataset`\n",
    "        \n",
    "    Outputs:\n",
    "        x: a tensor of shape (# patiens, max # visits, len(freq_codes)) of type torch.float\n",
    "        masks: a tensor of shape (# patiens, max # visits) of type torch.bool\n",
    "        y: a tensor of shape (# patiens) of type torch.float\n",
    "        \n",
    "    Note that you can obtains the list of diagnosis codes and the list of mortality labels\n",
    "        using: `sequences, labels = zip(*data)`\n",
    "    \"\"\"\n",
    "    sequences, labels = zip(*data)\n",
    "    num_patients = len(sequences)\n",
    "    num_visits = [len(patient) for patient in sequences]\n",
    "    max_num_visits = max(num_visits)\n",
    "    \n",
    "    y = torch.tensor(labels, dtype=torch.float)\n",
    "    x = torch.zeros((num_patients, max_num_visits, len(freq_codes)), dtype=torch.float) \n",
    "#     print(x[0])\n",
    "\n",
    "    for i_patient, patient in enumerate(sequences):\n",
    "        for j_visit, visit in enumerate(patient):\n",
    "            for code in visit:\n",
    "                \"\"\"\n",
    "                TODO: 1. check if code is in freq_codes;\n",
    "                      2. obtain the code index using code2idx;\n",
    "                      3. set the correspoindg element in x to 1.\n",
    "                \"\"\"\n",
    "                if code in freq_codes:     \n",
    "                    x[i_patient][j_visit][code2idx[code]] = 1\n",
    "                \n",
    "                        \n",
    "    print(x[0][0].sum())              \n",
    "    masks = torch.sum(x, dim=-1) > 0\n",
    "    print(x.shape, masks.shape, y.shape)\n",
    "    return x, masks, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T17:42:57.211372Z",
     "start_time": "2020-12-22T17:42:57.203084Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f2f220a9d60aa0ca6993198f933b83b3",
     "grade": true,
     "grade_id": "cell-50005521abaf98fe",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.)\n",
      "torch.Size([10, 5, 360]) torch.Size([10, 5]) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=10, collate_fn=collate_fn)\n",
    "loader_iter = iter(loader)\n",
    "x, masks, y = next(loader_iter)\n",
    "\n",
    "assert x.dtype == torch.float\n",
    "assert y.dtype == torch.float\n",
    "assert masks.dtype == torch.bool\n",
    "\n",
    "assert x.shape == (10, 5, 360)\n",
    "assert y.shape == (10,)\n",
    "assert masks.shape == (10, 5)\n",
    "\n",
    "assert x[0][0].sum() == 8\n",
    "assert masks[0].sum() == 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ec4aad114c789bb380ac0fc2617808ce",
     "grade": false,
     "grade_id": "cell-0fb787270b9161d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we have `CustomDataset` and `collate_fn()`. Let us split the dataset into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T17:42:58.113322Z",
     "start_time": "2020-12-22T17:42:58.109160Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cfdd21ad2e22810481570104a76ae7c7",
     "grade": false,
     "grade_id": "cell-4f2e9e518517db0e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 6029\n",
      "Length of val dataset: 1508\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "split = int(len(dataset)*0.8)\n",
    "\n",
    "lengths = [split, len(dataset) - split]\n",
    "train_dataset, val_dataset = random_split(dataset, lengths)\n",
    "\n",
    "print(\"Length of train dataset:\", len(train_dataset))\n",
    "print(\"Length of val dataset:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d5c40e75413b983f88fc5b0016b39c5f",
     "grade": false,
     "grade_id": "cell-dbe40dc6b384c8f0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.3 DataLoader [5 points]\n",
    "\n",
    "Now, we can load the dataset into the data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T17:43:00.145647Z",
     "start_time": "2020-12-22T17:43:00.141938Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def load_data(train_dataset, val_dataset, collate_fn):\n",
    "    \n",
    "    '''\n",
    "    TODO: Implement this function to return the data loader for  train and validation dataset. \n",
    "    Set batchsize to 32. Set `shuffle=True` only for train dataloader.\n",
    "    \n",
    "    Arguments:\n",
    "        train dataset: train dataset of type `CustomDataset`\n",
    "        val dataset: validation dataset of type `CustomDataset`\n",
    "        collate_fn: collate function\n",
    "        \n",
    "    Outputs:\n",
    "        train_loader, val_loader: train and validation dataloaders\n",
    "    \n",
    "    Note that you need to pass the collate function to the data loader `collate_fn()`.\n",
    "    '''\n",
    "    \n",
    "    # your code here\n",
    "    \"\"\"Dataloader Train\"\"\"\n",
    "    dir_path_train = data_path + '/' + 'train'\n",
    "    train_dataset = datasets.ImageFolder(dir_path_train, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    \"\"\"Dataloader Val\"\"\"\n",
    "    dir_path_val = data_path + '/' + 'val'\n",
    "    val_dataset = datasets.ImageFolder(dir_path_val, transform=transform)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "#     raise NotImplementedError\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T17:43:01.567930Z",
     "start_time": "2020-12-22T17:43:01.564998Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17746f020412f31cfe3cad168332bc80",
     "grade": true,
     "grade_id": "cell-f9a203ff240d95cf",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "train_loader, val_loader = load_data(train_dataset, val_dataset, collate_fn)\n",
    "assert len(train_loader) == 189\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "73809b9a84b8068168ac1535eb27d711",
     "grade": false,
     "grade_id": "cell-d852f17eea849e99",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3 Building the Seq2seq model [50 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b3b6bae1e47cdbca4113dd83ef19a53a",
     "grade": false,
     "grade_id": "cell-f206e1c0d9459abb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The most common sequence-to-sequence (seq2seq) models are *encoder-decoder* models, which commonly use a *recurrent neural network* (RNN) to *encode* the source (input) sentence into a single vector. In this notebook, we'll refer to this single vector as a *context vector*. We can think of the context vector as being an abstract representation of the entire input sentence. This vector is then *decoded* to output the target by generating it one word at a time.\n",
    "\n",
    "![](img/seq2seq1.png)\n",
    "\n",
    "The above image shows an example translation. \n",
    "\n",
    "In this task, we will build a naive GRU seq2seq autoencoder model. The input to the encoder will be the multi-hot code vector at each timestep. The decoder will try to reconstruct the input at each timestep based on the hidden embedding of the encoder network. In this way, we can store the longitudinal patient EHR data in a vector (i.e., the hidden state of the encoder network)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff33f6bd049e837e328f85b028de3f74",
     "grade": false,
     "grade_id": "cell-35b60df3b95c0443",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.1 Build the encoder model [15 points]\n",
    "\n",
    "First, we will build the encoder model using ```nn.GRU```. The input will be fed into the GRU and get final hidden state as the output of the encoder. Importantly, you need to use `masks` to mask out the padding visits. So, let us first preform the mask selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T17:43:10.068291Z",
     "start_time": "2020-12-22T17:43:10.064765Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "07ab4e66c6887f65d834bb0237587c19",
     "grade": false,
     "grade_id": "cell-aa45439f089aca6a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_last_visit(hidden_states, masks):\n",
    "    \"\"\"\n",
    "    Obtain the hidden state for the last true visit (not padding visits)\n",
    "\n",
    "    Arguments:\n",
    "        hidden_states: the hidden states of each visit of shape (batch_size, # visits, embedding_dim)\n",
    "        masks: the padding masks of shape (batch_size, # visits, # diagnosis codes)\n",
    "\n",
    "    Outputs:\n",
    "        last_hidden_state: the hidden state for the last true visit of shape (batch_size, embedding_dim)\n",
    "    \"\"\"\n",
    "    \n",
    "    last_true_visits = torch.sum(masks, dim=-1) - 1\n",
    "    last_true_visits = last_true_visits.view(-1, 1, 1).expand(hidden_states.size())\n",
    "    true_h_n = torch.gather(hidden_states, dim=1, index=last_true_visits)[:, -1, :]\n",
    "    return true_h_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T19:17:55.441602Z",
     "start_time": "2020-12-06T19:17:55.438279Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "96747b294d67da9543b459632ac6db8a",
     "grade": false,
     "grade_id": "cell-67272da780102c6f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Next we will build the GRU encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T17:43:10.623878Z",
     "start_time": "2020-12-22T17:43:10.616100Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        TODO: Define the RNN using `nn.GRU()`; \n",
    "              The `input_size` is 360. Set `hidden_size` to 128. Set `batch_first` to True.\n",
    "        \"\"\"\n",
    "        self.rnn = None\n",
    "        # your code here\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def forward(self, x, masks):\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "            1. Pass the sequence through the RNN layer;\n",
    "            2. Obtain the hidden state at the last visit.\n",
    "               Use `get_last_visit()`;\n",
    "            \n",
    "        Arguments:\n",
    "            x: the diagnosis sequence of shape (batch_size, # visits, # diagnosis codes)\n",
    "            masks: the padding masks of shape (batch_size, # visits)\n",
    "\n",
    "        Outputs:\n",
    "            states: probabilities of shape (batch_size, 128)\n",
    "        \"\"\"\n",
    "        \n",
    "        # your code here\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T17:43:11.353287Z",
     "start_time": "2020-12-22T17:43:11.349734Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "313379bcb0c5cf34455d78a5a9d53576",
     "grade": true,
     "grade_id": "cell-db5f84f39a074460",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "encoder = Encoder()\n",
    "\n",
    "layer_types_to_check = [nn.GRU]\n",
    "\n",
    "for layer_type in layer_types_to_check:\n",
    "    no_layer = True\n",
    "    for child in encoder.children():\n",
    "        for layer in child.modules():\n",
    "            if(isinstance(layer, layer_type)):\n",
    "                no_layer = False\n",
    "    assert no_layer is False\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=10, collate_fn=collate_fn)\n",
    "loader_iter = iter(loader)\n",
    "x, masks, y = next(loader_iter)\n",
    "assert encoder(x, masks).shape == (10, 128), \"output shape is not (batch_size, 128)!\"\n",
    "assert round(encoder(x, masks)[0][0].item(), 4) == 0.0577, \"output value is wrong!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6b18284f4f4507593fa5fd9ad316f484",
     "grade": false,
     "grade_id": "cell-4456b6dc45c4375c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.2 Build the decoder model [15 points]\n",
    "\n",
    "Next, we'll build our decoder, which will also be a GRU.\n",
    "\n",
    "The `Decoder` class does a single step of decoding, i.e. it ouputs single reconstructed results per time-step. The GRU layer will receive the initial hidden state from the encoder outputs. The first input to the decoder will be a zero vector, and then the decoder will try to reconstruct the input at timestep 1. For the following timestep, the input will be the output of the decoder from last timestep.\n",
    "\n",
    "Within the `forward` method, we accept a batch of inputs and previous hidden states. As we are only decoding one token at a time, the input tokens will always have a sequence length of 1. We `unsqueeze` the inputs to add a length dimension of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T17:46:52.035451Z",
     "start_time": "2020-12-22T17:46:52.025226Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        TODO: Define the RNN using `nn.GRU()`; \n",
    "              The `input_size` is 360. Set `hidden_size` to 128. Set `batch_first` to True.\n",
    "        \"\"\"\n",
    "        self.rnn = None\n",
    "        # your code here\n",
    "        raise NotImplementedError\n",
    "        \n",
    "        self.linear1 = nn.Linear(128, 128)\n",
    "        self.act = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(128, 360)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x, hiddens):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: the diagnosis sequence of shape (batch_size, # diagnosis codes)\n",
    "            hiddens: the padding masks of shape (batch_size, 128)\n",
    "\n",
    "        Outputs:\n",
    "            preds: the reconstructed results of shape (batch_size, # diagnosis codes)\n",
    "            hiddens: the hidden state of the GRU with shape (batch_size, 128)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Unsqueeze the input at dimension 1 -> (batch_size, 1, # diagnosis codes)\n",
    "        x = x.unsqueeze(1)\n",
    "        # Unsqueeze the hiddens at dimension 0; -> (1, batch_size, 128)\n",
    "        hiddens = hiddens.unsqueeze(0)\n",
    "        \n",
    "        \"\"\"\n",
    "        TODO:\n",
    "            1. Pass the input through the RNN layer; Remember to set the initial hidden states of GRU `h_0` to `hiddens`\n",
    "            2. Squeeze the hidden states h_n of RNN at dimension 0.\n",
    "        \"\"\"\n",
    "        h_n = None\n",
    "        # your code here\n",
    "        raise NotImplementedError\n",
    "        \n",
    "        preds = self.linear1(h_n)\n",
    "        preds = self.act(preds)\n",
    "        preds = self.linear2(preds)\n",
    "        preds = self.sigmoid(preds)\n",
    "        return preds, h_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T17:46:54.189642Z",
     "start_time": "2020-12-22T17:46:54.185961Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0eb2c077a46a81a474fd3a48517acd90",
     "grade": true,
     "grade_id": "cell-fd2996e12ec715e9",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "decoder = Decoder()\n",
    "\n",
    "layer_types_to_check = [nn.GRU, nn.Linear, nn.Sigmoid]\n",
    "\n",
    "for layer_type in layer_types_to_check:\n",
    "    no_layer = True\n",
    "    for child in decoder.children():\n",
    "        for layer in child.modules():\n",
    "            if(isinstance(layer, layer_type)):\n",
    "                no_layer = False\n",
    "    assert no_layer is False\n",
    "\n",
    "x = torch.randn(10, 360)\n",
    "hiddens = torch.randn(10, 128)\n",
    "assert decoder(x, hiddens)[0].shape == (10, 360), \"preds is not of shape (batch_size, 360)!\"\n",
    "assert decoder(x, hiddens)[1].shape == (10, 128), \"h_n is not of shape (batch_size, 128)!\"\n",
    "assert round(decoder(x, hiddens)[0][0][0].item(), 4) == 0.5177, \"preds value is wrong!\"\n",
    "assert round(decoder(x, hiddens)[1][0][0].item(), 4) == -0.3921, \"h_n value is wrong!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T20:09:29.897381Z",
     "start_time": "2020-12-06T20:09:29.895194Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4d99537c7f8c3f2810902be29578c837",
     "grade": false,
     "grade_id": "cell-40bad955f606721f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.3 Connect the encoder and decoder [20 points]\n",
    "\n",
    "For the final part of the implemenetation, we'll implement the seq2seq model\n",
    "\n",
    "The `Seq2Seq` model takes in an `Encoder` and a `Decoder`.\n",
    "\n",
    "Our `forward` method takes the source sequence, target sentence and a teacher-forcing ratio. The teacher forcing ratio is used when training our model. With probability equal to the teaching forcing ratio (`teacher_forcing_ratio`) we will use the actual ground-truth input in the sequence as the input to the decoder during the next time-step. However, with probability `1 - teacher_forcing_ratio`, we will use the output that the model predicted as the next input to the model.  \n",
    "\n",
    "The first input to the decoder is a zero vector.\n",
    "\n",
    "During each iteration of the loop, we:\n",
    "- pass the input, previous hidden states into the decoder\n",
    "- receive a prediction and next hidden state from the decoder\n",
    "- decide if we are going to \"teacher force\" or not\n",
    "    - if we do, the next `input` is the ground-truth input in the sequence\n",
    "    - if we don't, the next `input` is the predicted input in the sequence\n",
    "    \n",
    "Once we've made all of our predictions, we return our tensor full of predictions.\n",
    "\n",
    "For example, So our `inputs` and `outputs` of the decoder look something like ($x_t$ is the orinal input, $\\hat{x}_t$ is the reconstructed input):\n",
    "\n",
    "If not use teach force:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\text{inputs} &= [0, \\hat{x}_1, \\hat{x}_2]\\\\\n",
    "\\text{outputs} &= [\\hat{x}_1, \\hat{x}_2, \\hat{x}_3]\n",
    "\\end{align*}$$\n",
    "\n",
    "If use teach force:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\text{inputs} &= [0, x_1, x_2]\\\\\n",
    "\\text{outputs} &= [\\hat{x}_1, \\hat{x}_2, \\hat{x}_3]\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T17:47:11.449921Z",
     "start_time": "2020-12-22T17:47:11.440603Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder, decoder, teacher_forcing_ratio):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "        \n",
    "    def forward(self, x, masks):\n",
    "        \n",
    "        \"\"\"\n",
    "        STEP:\n",
    "            1. Pass the input through the encoder; save the output to `hidden`;\n",
    "            2. Pass the first input (0) and encoder hidden state to the decoder;\n",
    "            3. Use for-loop to \n",
    "                   1. Use `random.random()` to decide whether to use teacher force\n",
    "                   2. Pass the previous output `cur_pred` / the ground truth input `x[:, t-1, :]` \n",
    "                      and previous hidden state `h` to the decoder;\n",
    "                   3. Save `cur_pred`, the output of the decoder, to a list.\n",
    "            4. Use torch.stack to convert the list to a tensor and \n",
    "               reshape it to (batch_size, # visits, # diagnosis codes)\n",
    "            \n",
    "        Arguments:\n",
    "            x: the diagnosis sequence of shape (batch_size, # visits, # diagnosis codes)\n",
    "            masks: the padding masks of shape (batch_size, # visits)\n",
    "\n",
    "        Outputs:\n",
    "            preds: the reconstructed results of shape (batch_size, # visits, # diagnosis codes)\n",
    "        \"\"\"\n",
    "        \n",
    "        preds = []\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        seq_len = x.shape[1]\n",
    "        \n",
    "        \"\"\"\n",
    "        TODO: perform step 1\n",
    "        \"\"\"\n",
    "        hidden = None\n",
    "        # your code here\n",
    "        raise NotImplementedError\n",
    "        \n",
    "        # step 2\n",
    "        x_decode = torch.zeros(batch_size, 360)\n",
    "        cur_pred, h = self.decoder(x_decode, hidden)\n",
    "        preds.append(cur_pred)\n",
    "        \n",
    "        for t in range(1, seq_len):\n",
    "            # step 3.1\n",
    "            teacher_force = random.random() < self.teacher_forcing_ratio\n",
    "            \n",
    "            \"\"\"\n",
    "            TODO: perform step 3.2\n",
    "            \"\"\"\n",
    "            # your code here\n",
    "            raise NotImplementedError\n",
    "            \n",
    "            # step 3.3\n",
    "            preds.append(cur_pred)\n",
    "        \n",
    "        # step 4\n",
    "        return torch.stack(preds).permute(1,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T17:47:14.316665Z",
     "start_time": "2020-12-22T17:47:14.312831Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c46d2c03357707c41e7cd76f6f3c642a",
     "grade": true,
     "grade_id": "cell-06fd2b774fea5691",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "seq2seq = Seq2Seq(encoder, decoder, 0.5)\n",
    "\n",
    "layer_types_to_check = [nn.GRU, nn.Linear, nn.Sigmoid]\n",
    "\n",
    "for layer_type in layer_types_to_check:\n",
    "    no_layer = True\n",
    "    for child in seq2seq.children():\n",
    "        for layer in child.modules():\n",
    "            if(isinstance(layer, layer_type)):\n",
    "                no_layer = False\n",
    "    assert no_layer is False\n",
    "\n",
    "x = torch.randn(10, 5, 360)\n",
    "masks = torch.ones(10, 5, dtype=torch.bool)\n",
    "assert seq2seq(x, masks).shape == (10, 5, 360), \"output shape should be (batch_size, # visits, # diagnosis codes)!\"\n",
    "assert round(seq2seq(x, masks)[0][0][0].item(), 4) == 0.4908, \"output value is wrong!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3660c73a4ab361282394fd113086c34c",
     "grade": false,
     "grade_id": "cell-be62492fb269883c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 4 Model training [15 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3b76222840b264add16720ea2eae3e3a",
     "grade": false,
     "grade_id": "cell-055e3d88da155e04",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 4.1 Loss and optimizer\n",
    "Because we are reconstructing original input, we use BCELoss as loss function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T17:47:16.231308Z",
     "start_time": "2020-12-22T17:47:16.228178Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "794c6946b8e66b876094348abf55ccc6",
     "grade": false,
     "grade_id": "cell-608d0514fef945d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# set reduction='none' because we need to mask out the padding values manually.\n",
    "criterion = nn.BCELoss(reduction='none')\n",
    "optimizer = torch.optim.Adam(seq2seq.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T13:38:05.210804Z",
     "start_time": "2020-12-07T13:38:05.207769Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a2bf00c543b0fdd07d28afd25b735769",
     "grade": false,
     "grade_id": "cell-49b8e14db7d29817",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 4.2 Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T17:51:26.420622Z",
     "start_time": "2020-12-22T17:51:26.415412Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e6129b31d7de272b75ee30c4c9bd067",
     "grade": false,
     "grade_id": "cell-aa7e17a496e35c5f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "\n",
    "def eval(model, val_loader):\n",
    "    \n",
    "    \"\"\"\n",
    "    Evaluate the model.\n",
    "    \n",
    "    Arguments:\n",
    "        model: the seq2seq model\n",
    "        val_loader: validation dataloader\n",
    "        \n",
    "    Outputs:\n",
    "        f1: overall f1 score\n",
    "        accuracy: overall accuracy score; \n",
    "        use np.round to round the preds to calculate the metrics.\n",
    "        \n",
    "    We have implement this for you.\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    x_pred = []\n",
    "    x_true = []\n",
    "    for x, masks, y in val_loader:\n",
    "        x_hat = model(x, masks).detach().numpy()\n",
    "        x_hat = np.round(x_hat)\n",
    "        for i in range(len(x_hat)):\n",
    "            for j in range(len(x_hat[i])):\n",
    "                if masks[i, j] == 1:\n",
    "                    x_pred.append(x_hat[i,j])\n",
    "                    x_true.append(x.numpy()[i,j])\n",
    "    \n",
    "    f = f1_score(y_pred=x_pred, y_true=x_true, average='micro')\n",
    "    acc = accuracy_score(y_pred=x_pred, y_true=x_true)\n",
    "    return f, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "27866387e1328de2c8c617c3cc8b9342",
     "grade": false,
     "grade_id": "cell-6a0ef300a62e964f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 4.3 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T17:48:30.804629Z",
     "start_time": "2020-12-22T17:47:20.182472Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf6b4f7ad1c65b47c664d13205c8c9b9",
     "grade": false,
     "grade_id": "cell-f1bd817117170596",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, n_epochs):\n",
    "    \"\"\"\n",
    "    Train the model.\n",
    "    \n",
    "    Arguments:\n",
    "        model: the RNN model\n",
    "        train_loader: training dataloder\n",
    "        val_loader: validation dataloader\n",
    "        n_epochs: total number of epochs\n",
    "        \n",
    "    We have implement this for you.\n",
    "    \"\"\"\n",
    "    \n",
    "    seq2seq.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = 0\n",
    "        for x, masks, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            x_hat = seq2seq(x, masks)\n",
    "            loss = criterion(x_hat, x)\n",
    "            loss = loss * masks.float().unsqueeze(-1)\n",
    "            loss = torch.mean(torch.sum(loss, dim=[1,2]))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "        f, acc = eval(model, val_loader)\n",
    "        print('Epoch: %d \\t Validation f: %.2f, acc: %.2f'%(epoch+1, f, acc))\n",
    "\n",
    "    \n",
    "# number of epochs to train the model\n",
    "n_epochs = 20\n",
    "\n",
    "train(seq2seq, train_loader, val_loader, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T17:48:33.167005Z",
     "start_time": "2020-12-22T17:48:31.990046Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ab6e8526f6d5f5b963c3ef9965b7001",
     "grade": true,
     "grade_id": "cell-1bcd0ee830fdae35",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "941dd7511538bd431f756112754a62b6",
     "grade": false,
     "grade_id": "cell-6478a0ab26954d0f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 5 Unsupervised patient clustering [15 points]\n",
    "\n",
    "After training a seq2seq model, we can use the encoder to generate patient embeddings. These embeddings can be used for unsupervised tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T17:48:58.969637Z",
     "start_time": "2020-12-22T17:48:58.384572Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8536295eff65e43c3752c9961dc49a13",
     "grade": false,
     "grade_id": "cell-cfc8376c4f541b57",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_embeddings(model, data_loader):\n",
    "    \"\"\"\n",
    "    Use trained encoder model to get patient embeddings.\n",
    "    \n",
    "    Arguments:\n",
    "        model: trained seq2seq model\n",
    "        data_loader: dataloder\n",
    "        \n",
    "    Return:\n",
    "        embeddings: numpy array that contains patient embeddings.\n",
    "        labels: numpy array that contains patient mortality label.\n",
    "    \n",
    "    We have implement this for you.\n",
    "    \"\"\"\n",
    "    \n",
    "    seq2seq.eval()\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    for x, masks, y in data_loader:\n",
    "        cur_embd = seq2seq.encoder(x, masks)\n",
    "        embeddings += list(cur_embd.detach().numpy())\n",
    "        labels += list(y.numpy())\n",
    "        \n",
    "    return np.array(embeddings), np.array(labels)\n",
    "\n",
    "    \n",
    "embeddings, labels = get_embeddings(seq2seq, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3138d4870f60bffbe8f26e772d230af9",
     "grade": false,
     "grade_id": "cell-1bb215c283b707df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Next we will use KMeans algorithm to cluster these embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T17:49:00.371307Z",
     "start_time": "2020-12-22T17:48:59.935429Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def get_clusters(embeddings):\n",
    "    \"\"\"\n",
    "    TODO: 1. Use K-means to generate patient clusters. (set K to 2)\n",
    "          2. Use calinski harabaz score to evaluate clustering results\n",
    "    \n",
    "    Arguments:\n",
    "        embeddings: obtained patient embeddings\n",
    "        \n",
    "    Return:\n",
    "        labels: K-means clustering labels\n",
    "        \n",
    "    Hint: Use sklearn.cluster.KMeans and sklearn.metrics.calinski_harabasz_score.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # your code here\n",
    "    raise NotImplementedError\n",
    "    \n",
    "cluster_labels = get_clusters(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T17:49:12.029584Z",
     "start_time": "2020-12-22T17:49:12.025393Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7246b496467481a087757bb82eed2996",
     "grade": true,
     "grade_id": "cell-766460c1932d6947",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "assert cluster_labels.shape == (1508, )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "69e95d703f47480cb8196dcc419d7e1f",
     "grade": false,
     "grade_id": "cell-e953823d84417c44",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let us use T-SNE to visualize the embeddings and clustering results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T17:49:17.979926Z",
     "start_time": "2020-12-22T17:49:14.113545Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32e9f3b56949f6c340a7cd40b3ecf509",
     "grade": false,
     "grade_id": "cell-c84efd7951adb169",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import manifold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tsne = manifold.TSNE(n_components=2, init='pca', random_state=42)\n",
    "tsne_embd = tsne.fit_transform(embeddings)\n",
    "\n",
    "plt.scatter(tsne_embd[:,0], tsne_embd[:,1], c=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "533c85a4223f6df60900486be393ab54",
     "grade": false,
     "grade_id": "cell-0033092e6ce467a6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The cluster result is not really good due to the limited resources. Feel free to explore more on this topic in project!"
   ]
  }
 ],
 "metadata": {
  "illinois_payload": {
   "b64z": "",
   "nb_path": "release/HW3-Seq2Seq/HW3-Seq2Seq.ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (Threads: 2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "409.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
